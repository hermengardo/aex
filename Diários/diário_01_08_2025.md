# Diário (01/08/2025) - Extração e Estruturação de Dados Não Estruturados

## Objetivo
- Extrair variáveis dos documentos `.pdf`.
- Separar os dados extraídos em dois conjuntos para anotação manual (teste e validação) e um conjunto para anotação automática.

## Decisões
- Usar API's de LLM's para os problemas de classificação.
- Seleção aleatória estratificada por unidade (para evitar sobrerepresentação de unidades com muitos projetos AEX).
- Unidades com poucos projetos (menos que 10) foram aglutinadas em uma mesma categoria 'outros' para garantir que cada grupo tenha casos suficientes para estratificação. Isso evita erros na divisão estratificada, que exige pelo menos duas amostras por classe em cada conjunto. Código usado para separar as amostras:
```python
freq = df['Unidade Sigla'].value_counts()
df['stratify_col'] = df['Unidade Sigla'].apply(lambda x: x if freq[x] >= 10 else 'outros')

train, test_val = train_test_split(df, test_size=0.15, stratify=df['stratify_col'], random_state=956)
test, val = train_test_split(test_val, test_size=0.20, stratify=test_val['stratify_col'], random_state=962)
```

## Ambiente e dependências
  
| Dependência  | Uso                                            | Versão    |
| :----------: | :--------------------------------------------: | :-------: |
| `pandas`     | Manipulação de dados tabulares                 | `2.2.2`   |
| `seaborn`    | Visualização estatística                       | `0.13.2`  |
| `numpy`      | Operações numéricas                            | `2.0.2`   |
| `os`         | Interação com o sistema de arquivos            | Nativo    |
| `re`         | Operações com expressões regulares             | Nativo    |
| `pypdf`      | Leitura de arquivos PDF                        | `5.9.0`   |
| `matplotlib`  | Geração de gráficos                           | `3.10.0`   |
| `seaborn`            | Geração de gráficos                    | `0.13.2`  |
| `scikit-learn` | Separação das amostras                       | `1.6.1`   |

## Scripts
- Ambos os scripts foram executados em ambiente Google Colab (Python 3.11.13). As configurações do ambiente estão em `/Ambientes/config_colab.txt` e as dependências em `/Ambientes/requirements_colab.txt`.
  - `Estruturando_os_dados.ipynb`:  
    - Lê e converte arquivos `.pdf` em strings.  
    - Usa regex para extrair dados textuais como variáveis (com as suposições para cada regex comentadas no arquivo).  
    - Salva o resultado em arquivo `.csv`.  
  - `Seleção_de_Amostra.ipynb`:  
    - Usa o arquivo processado por `Estruturando_os_dados.ipynb` para separar os dados em conjuntos de treino, teste e validação.

## Próximos passos
- [ ] Construir o manual de anotação
- [ ] Construir os prompts para as tarefas
- [ ] Anotar manualmente o conjunto de validação e teste
- [ ] Avaliar a qualidade da anotação

## Problemas e erros
- Usei expressões regulares para a estruturação. Como é um método automático, provavelmente há erros, então vale a pena conferir. Pela minha experiência, os principais erros desse tipo de técnica são introduzidos por:
  1. Passagem dos documentos PDF para string

  2. Má formação do padrão regex

  3. Má construção ou estrutura inconsistente do documento
- Estou seguro quanto às informações mais sucintas, como nome da unidade e do professor, etc.. As informações mais longas e não estruturadas, como descrições, metas etc., costumam ser mais difíceis de tratar e verificar, então, provavelmente, se houver erros, estarão nessa parte.

